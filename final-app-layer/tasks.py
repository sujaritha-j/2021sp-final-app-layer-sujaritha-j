import luigi
from datetime import datetime
import sqlalchemy as sa
import pyodbc

import mysql
from luigi.contrib.mysqldb import MySqlTarget
from luigi import Parameter
from luigi.contrib.s3 import S3Target
import dask.dataframe as dd
import dask

# import mysql.connector
# from mysql.connector import errorcode, Error


class DataDownloadTask(luigi.ExternalTask):
    s3_data_path = Parameter()  # Filename of the image under the root s3 path
    run_date = datetime.now().date()
    target_table = "product_table"
    #   database configurations
    host = 'advpy-finalproject-02.clihicjrcxdy.us-east-1.rds.amazonaws.com'
    port = 3306
    dbname = 'productdb'
    user = 'admin'
    password = 'admin.123'

    server_uri = '{}:{}@{}/{}'.format(user, password, host, dbname)

    autocommit = True
    table = 'products'
    columns = ['uniq_id', 'product_name', 'brand_name', 'p_asin', 'category', 'upc_ean_code', 'list_price',
               'selling_price', 'quantity', 'model_number, about_product', 'product_specification',
               'technical_details', 'shipping_weight', 'product_dimensions', 'image', 'variants', 'sku',
               'product_url', 'stock', 'product_details, dimensions', 'color', 'ingredients', 'directions_to_use',
               'is_amazon_seller', 'size_quantity_variant', 'product_description', 'vectorized_value']

    def get_target(self):
        return MySqlTarget(host=self.host,
                           database=self.dbname,
                           user=self.user,
                           password=self.password,
                           table=self.target_table,
                           update_id=str(self.run_date)
                           )

    def requires(self):
        pass  # pragma: no_cover

    def output(self):
        return self.get_target()

    def copy(self, cursor, file=None):
        values = '({})'.format(','.join(['%s' for i in range(len(self.columns))]))
        columns = '({})'.format(','.join([c[0] for c in self.columns]))
        query = 'INSERT INTO {} {} VALUES {}'.format(self.table, columns, values)
        rows = []

        for idx, row in enumerate(self.rows()):
            rows.append(row)

            if (idx + 1) % self.bulk_size == 0:
                cursor.executemany(query, rows)
                rows = []

        cursor.executemany(query, rows)

    def run(self):

        # Read from S3
        ddf = dd.read_csv(  # pragma: no_cover
            self.s3_data_path,
            dtype={'Upc Ean Code': 'str'},
            storage_options={
                'anon': False,
                'requester_pays': True
            }
        )
        print(ddf.head(5))
        """
        Inserts data generated by rows() into target table.
        """
        to_sql_uri = sa.create_engine(f'mssql://@{self.server_uri}?trusted_connection=yes',
                                      fast_executemany=True)

        for i in range(ddf.npartitions):
            ddf_partition = ddf.get_partition(i)
            if i == 0:
                ddf_partition.to_sql('products', uri=to_sql_uri, if_exists='replace', index=False)
            if i > 0:
                ddf_partition.to_sql('products', uri=to_sql_uri, if_exists='append', index=False)
            i += 1
        # dto_sql = dask.delayed(ddf.DataFrame.to_sql)
        # out = [dto_sql(d, self.table, self.host, if_exists='append', index=True)
        #        for d in ddf.to_delayed()]
        # dask.compute(*out)


        # try:
        #     connection = self.output().connect()
        #     connection.autocommit = self.autocommit
        #     cursor = connection.cursor()
        #     # query = "insert into products(uniq_id, product_name, brand_name, p_asin, category, upc_ean_code, " \
        #     #         "list_price, selling_price, quantity, model_number, about_product, product_specification, " \
        #     #         "technical_details, shipping_weight, product_dimensions, image, variants, sku, product_url, " \
        #     #         "stock, product_details, dimensions, color, ingredients, directions_to_use, is_amazon_seller, " \
        #     #         "size_quantity_variant, product_description, " \
        #     #         "vectorized_value) values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, " \
        #     #         "%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)"
        #     values = '({})'.format(','.join(['%s' for i in range(len(self.columns))]))
        #     columns = '({})'.format(','.join([c for c in self.columns]))
        #     query = 'INSERT INTO {} {} VALUES {}'.format(self.table, columns, values)
        #     rows = self.input().rows
        #     cursor.execute(query)
        #     # Update marker table
        #     self.output().touch(connection)
        #     connection.commit()
        # except mysql.connector.Error as e:
        #     print('Error', e)
        # finally:
        #     connection.close()
